{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# Load the dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Normalize the images to be between 0 and 1\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot some sample images\n",
    "plt.figure(figsize=(10, 5))\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    plt.imshow(x_train[i], cmap='gray')\n",
    "    plt.title(f'Label: {y_train[i]}')\n",
    "    plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def create_lenet_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Reshape((28, 28, 1), input_shape=(28, 28)))\n",
    "    model.add(layers.Conv2D(6, (5, 5), activation='tanh', padding='same'))\n",
    "    model.add(layers.AveragePooling2D(pool_size=(2, 2)))\n",
    "    model.add(layers.Conv2D(16, (5, 5), activation='tanh'))\n",
    "    model.add(layers.AveragePooling2D(pool_size=(2, 2)))\n",
    "    model.add(layers.Conv2D(120, (5, 5), activation='tanh'))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(84, activation='tanh'))\n",
    "    model.add(layers.Dense(10, activation='softmax'))\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = create_lenet_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train, epochs=5, batch_size=64, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
    "print(f'Test Loss: {test_loss}')\n",
    "print(f'Test Accuracy: {test_accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def create_lenet_model_with_params(learning_rate=0.001, batch_size=64, num_neurons=84):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Reshape((28, 28, 1), input_shape=(28, 28)))\n",
    "    model.add(layers.Conv2D(6, (5, 5), activation='tanh', padding='same'))\n",
    "    model.add(layers.AveragePooling2D(pool_size=(2, 2)))\n",
    "    model.add(layers.Conv2D(16, (5, 5), activation='tanh'))\n",
    "    model.add(layers.AveragePooling2D(pool_size=(2, 2)))\n",
    "    model.add(layers.Conv2D(120, (5, 5), activation='tanh'))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(num_neurons, activation='tanh'))\n",
    "    model.add(layers.Dense(10, activation='softmax'))\n",
    "    \n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Parameters to experiment with\n",
    "learning_rates = [0.001, 0.01, 0.1]\n",
    "batch_sizes = [32, 64, 128]\n",
    "num_neurons_list = [64, 84, 128]\n",
    "\n",
    "results = []\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for batch_size in batch_sizes:\n",
    "        for num_neurons in num_neurons_list:\n",
    "            print(f\"Training with learning_rate={lr}, batch_size={batch_size}, num_neurons={num_neurons}\")\n",
    "            model = create_lenet_model_with_params(learning_rate=lr, batch_size=batch_size, num_neurons=num_neurons)\n",
    "            history = model.fit(x_train, y_train, epochs=5, batch_size=batch_size, validation_split=0.1, verbose=2)\n",
    "            test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "            results.append({\n",
    "                'learning_rate': lr,\n",
    "                'batch_size': batch_size,\n",
    "                'num_neurons': num_neurons,\n",
    "                'test_loss': test_loss,\n",
    "                'test_accuracy': test_accuracy\n",
    "            })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "\n",
    "def create_lenet_model_with_dropout_and_l2(dropout_rate=0.5, l2_reg=0.01):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Reshape((28, 28, 1), input_shape=(28, 28)))\n",
    "    model.add(layers.Conv2D(6, (5, 5), activation='tanh', padding='same', kernel_regularizer=regularizers.l2(l2_reg)))\n",
    "    model.add(layers.AveragePooling2D(pool_size=(2, 2)))\n",
    "    model.add(layers.Conv2D(16, (5, 5), activation='tanh', kernel_regularizer=regularizers.l2(l2_reg)))\n",
    "    model.add(layers.AveragePooling2D(pool_size=(2, 2)))\n",
    "    model.add(layers.Conv2D(120, (5, 5), activation='tanh', kernel_regularizer=regularizers.l2(l2_reg)))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(84, activation='tanh', kernel_regularizer=regularizers.l2(l2_reg)))\n",
    "    model.add(layers.Dropout(dropout_rate))\n",
    "    model.add(layers.Dense(10, activation='softmax'))\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Train with and without Dropout/L2\n",
    "regularization_results = {}\n",
    "\n",
    "# Without regularization\n",
    "print(\"Training without regularization\")\n",
    "model_no_reg = create_lenet_model_with_params()\n",
    "history_no_reg = model_no_reg.fit(x_train, y_train, epochs=5, batch_size=64, validation_split=0.1, verbose=2)\n",
    "test_loss_no_reg, test_accuracy_no_reg = model_no_reg.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "# With Dropout and L2\n",
    "print(\"Training with Dropout and L2 regularization\")\n",
    "model_reg = create_lenet_model_with_dropout_and_l2()\n",
    "history_reg = model_reg.fit(x_train, y_train, epochs=5, batch_size=64, validation_split=0.1, verbose=2)\n",
    "test_loss_reg, test_accuracy_reg = model_reg.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "regularization_results['no_regularization'] = (test_loss_no_reg, test_accuracy_no_reg)\n",
    "regularization_results['with_regularization'] = (test_loss_reg, test_accuracy_reg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def plot_history(history, title):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title(f'{title} - Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(['Train', 'Validation'])\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title(f'{title} - Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(['Train', 'Validation'])\n",
    "    plt.show()\n",
    "\n",
    "plot_history(history_no_reg, 'Without Regularization')\n",
    "plot_history(history_reg, 'With Regularization')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model_reg.predict(x_test)\n",
    "y_pred_classes = tf.argmax(y_pred, axis=1)\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred_classes)\n",
    "\n",
    "# Plot confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=list(range(10)))\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
